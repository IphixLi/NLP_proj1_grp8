# Github address
```
https://github.com/IphixLi/NLP_proj1_grp8.git
```

# Package install

Please run the following command to get libraries and model files
```
pip install -r requirements.txt
python -m spacy download en_core_web_sm
python -m spacy download en_core_web_md
```

**Notes**: pycld3 is not supported to directly install with pip **on Windows** (check https://pypi.org/project/pycld3/)

# To run the code (minimum requirements)

1. awards: ```python main_awards.py gg2013.json```
2. winner, nominee, host, presenter: ```python gg_api.py``` (this may take around 9 minutes)

result for 2013:

```
{'2013': {'awards': {'completeness': 0.7240740740740741,
                     'spelling': 0.9329578928964305},
          'hosts': {'completeness': 1.0, 'spelling': 1.0},
          'nominees': {'completeness': 0.4602142857142858, 'spelling': 0.9936},
          'presenters': {'completeness': 0.5653846153846153,
                         'spelling': 0.9615384615384616},
          'winner': {'spelling': 0.9615384615384616}}}
```



# Getting awards

- awards names are given as list by invoking main_awards.py file with file which contain tweets.
for example:

```python main_awards.py gg2013.json```


1. We identified patterns through which the awards are mentioned in the tweets. we then created scripts that would allow us to extract probable award names. to inspect the patterns per given awards, see files marked by award names in ***inspect_files*** folder.

for some awards, we some official names of the awards were not used in the tweets such as awards related to individual performances. for example:

```Best performance in motion picture by an actor```
had tweets with:
```Best actor in motion picture```
hence we had to manipulate awards to handle these cases.

we also normalized all award names to be lowercase.



2. we then combined all probable award names and put them in clusters of similarities such that we are able to capture the most likely true name of the award. We used Spacy library which allowed us to vectorize text into tokens and cluster award names based on Jaccard similarity.
to inspect cluster patterns per proposed awards, see clusters.txt file in ***inspect_files*** folder.


3. from the clusters we got the awards name which had high count from tweets. we followed the heuristic that is the award name was mentioned many times in the tweets it is likely that it was mentioned differently by users such as minor pronounciation. We also looked at awards that had no clusters but was hightly mentioned in the tweets.



# Getting winner, nominees, hosts and presenters

- to run the code

    ```
    python gg_api.py
    ```

    make sure to change variables in main()

    ```python
    # change these variables in main()
    year = 2015
    input_dataset_filename = "gg2015.json"
    answer_filename = "gg2015answers.json"
    ```

    If some code went wrong, change function parameters 'debug=False' before the buggy process to 'debug=True' will make it faster (it will load the result generated by the last run). For example:

    ```python
    tp.load_all_tweets(debug=False)
    # to this:
    # tp.load_all_tweets(debug=True)
    ```

- expected runtime:

    - for 2013 data with 170k tweets, this file will takes **around 9 minutes** (may vary with different Internet connection)

- basic structure

    - data_preprocess (used for winner, nominee, host, presenter) (written in ```data_preprocess.py```)
        - preprocess tweet
            - fix timestamp to int if not
            - fix symbol
            - remove non-ascii
            - fix whitespace
            - remove url
            - fix tweet features
                - extract retweets (decrease redundant info), saved in another list
                - remove trailing hashtags and usernames (outside sentences)
                - fix normal hashtags and usernames
            - substitute some keywords to a more formal format: tv, miniseries
            - convert all upper word to lower (otherwise affect accuracy of spacy)
        - split tweets (saved in ```preprocessed_tweets_{year}``` folder)
            - tweets that include retweets
            - tweets that are empty after preprocessing
            - tweets that are not in English
            - tweets that start with "I (hope|guess|think|bet|predict)"
            - tweets that start with "I "
            - tweets that contain "should"
            - tweets that don't fall into any of the above categories
            - retweets and their counts
    - winner / nominees / presenters / hosts (first three steps written in their own python file)
        - use normal tweets as input
        - if satisfies some patterns
        - extract information based on those verbs (saved in ```winner_result_{year}/winner_verb.json```)
            - mainly about descendants of them
            - try to get winner names and award names / keywords
        - vote (written in ```vote.py```)
            - match each candidate name with a most likely award
                - saved in ```winner_result_{year}/voteres_winner_verb.json```
            - do weighted voting
                - saved in ```winner_result_{year}/vote_winner_verb.json```
            - [only in winner] **get timeline for the whole ceremony (written in ```timestamp_cluster.py```) (additional goal 1/2)**
                - saved in ```winner_result_{year}/timestamp_winner_verb.json```
        - [no need for hosts] gather (input: ```winner_result_{year}/vote_winner_verb.json``` in the last step) (written in ```gather_answers.py```)
            - cluster similar answers
            - filter answers
                - if it's part of the award names
                - if empty
                - if is a ceremony name
                - if the identity / year is not matched
                    - for person: identity check and legal name finding using wikipedia (```wiki.py```)
                    - for work: year check and legal name finding using cinemagoer (```imdbpy.py```)

# Additional Goals

1. for additional goals, we found the best dressed.
    - best dressed people are given as list by invoking extra_awards.py file. note that this file depends on prepocessed data which can got after running file: [file_for_pattern match].
    for example:


```python extra_awards.py```

We found tweets which mentions dress in them and then found sentiment score for tweets to see if the tweet was talking positively with outfit. we then found names of people mentioned in the tweet by checking in IMDB website, the real name of people mentioned. we then return people who had highest number of mentions in the tweets forbest  dressed.

2. another additional goal is timeline, we found the timestamp for each awards by collecting the time of all related tweets (for 2013, the timeline can be found on https://abcnews.go.com/blogs/entertainment/2013/01/live-updates-the-2013-golden-globe-awards/)

- timestamp related code is already integrated in ```gg_api.py``` part, no extra run. Unfortunately, I didn't add year parameter in this file, so after running gg_api with the given year, timestamp cluster only collects that year's data

- To check the timeline, check json file: ```winner_result_{year}/timestamp_winner_verb.json```, the result is listed in time order;

- To check the data collected for this feature, check folder: ```timestamp_result```

- To try to predict which award this tweet is related to:

    - run ```use_timestamp_cluster.ipynb``` and modify the tweet in the first block

    - Two functions are used in the second block, one is for tweets about nominees, while the other is for presenters (time pattern is slightly different between these two types). Tweets only about winners is not recommended to use, because those functions are based on the tweets timestamp about winners
